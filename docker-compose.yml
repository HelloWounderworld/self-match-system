version: '3.9'

services:
  api-request:
    container_name: api-request
    hostname: api-request
    build:
      context: ./api
      dockerfile: Dockerfile
      args:
        UID: ${UID}
        USERNAME: ${USERNAME}
        GID: ${GID}
        GROUPNAME: ${GROUPNAME}
        HTTP_PROXY: ${HTTP_PROXY:-}
        HTTPS_PROXY: ${HTTPS_PROXY:-}
        FTP_PROXY: ${FTP_PROXY:-}
        NO_PROXY: ${NO_PROXY:-}
        http_proxy: ${HTTP_PROXY:-}
        https_proxy: ${HTTPS_PROXY:-}
        ftp_proxy: ${FTP_PROXY:-}
        no_proxy: ${NO_PROXY:-}
    environment:
      HTPP_PROXY: ${HTPP_PROXY:-}
      HTTPS_PROXY: ${HTTPS_PROXY:-}
      FTP_PROXY: ${FTP_PROXY:-}
      NO_PROXY: ${NO_PROXY:-}
      http_proxy: ${HTTP_PROXY:-}
      https_proxy: ${HTTPS_PROXY:-}
      ftp_proxy: ${FTP_PROXY:-}
      no_proxy: ${NO_PROXY:-}
    ports:
      - ${API_LLM_PORT}:8000
    user: ${USERNAME}
    working_dir: /api
    volumes:
      - ./api:/api
    tty: true
    logging:
      driver: json-file
      options:
        max-file: '5'
        max-size: '10m'
  nlp-fine-tuning:
    container_name: nlp-fine-tuning
    hostname: nlp-fine-tuning
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
    build:
      context: ./nlp
      dockerfile: Dockerfile
      args:
        UID: ${UID}
        USERNAME: ${USERNAME}
        GID: ${GID}
        GROUPNAME: ${GROUPNAME}
        HTTP_PROXY: ${HTTP_PROXY:-}
        HTTPS_PROXY: ${HTTPS_PROXY:-}
        FTP_PROXY: ${FTP_PROXY:-}
        NO_PROXY: ${NO_PROXY:-}
        http_proxy: ${HTTP_PROXY:-}
        https_proxy: ${HTTPS_PROXY:-}
        ftp_proxy: ${FTP_PROXY:-}
        no_proxy: ${NO_PROXY:-}
    environment:
      HTPP_PROXY: ${HTPP_PROXY:-}
      HTTPS_PROXY: ${HTTPS_PROXY:-}
      FTP_PROXY: ${FTP_PROXY:-}
      NO_PROXY: ${NO_PROXY:-}
      http_proxy: ${HTTP_PROXY:-}
      https_proxy: ${HTTPS_PROXY:-}
      ftp_proxy: ${FTP_PROXY:-}
      no_proxy: ${NO_PROXY:-}
    ports:
      - ${API_LLM_PORT}:8000
    user: ${USERNAME}
    working_dir: /teramatsu/qlora
    volumes:
      - ./:/teramatsu/qlora
    tty: true
    logging:
      driver: json-file
      options:
        max-file: '5'
        max-size: '10m'
  run-model:
    container_name: run-model
    hostname: run-model
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
    build:
      context: .
      dockerfile: Dockerfile
      args:
        UID: ${UID}
        USERNAME: ${USERNAME}
        GID: ${GID}
        GROUPNAME: ${GROUPNAME}
        HTTP_PROXY: ${HTTP_PROXY:-}
        HTTPS_PROXY: ${HTTPS_PROXY:-}
        FTP_PROXY: ${FTP_PROXY:-}
        NO_PROXY: ${NO_PROXY:-}
        http_proxy: ${HTTP_PROXY:-}
        https_proxy: ${HTTPS_PROXY:-}
        ftp_proxy: ${FTP_PROXY:-}
        no_proxy: ${NO_PROXY:-}
    environment:
      HTPP_PROXY: ${HTPP_PROXY:-}
      HTTPS_PROXY: ${HTTPS_PROXY:-}
      FTP_PROXY: ${FTP_PROXY:-}
      NO_PROXY: ${NO_PROXY:-}
      http_proxy: ${HTTP_PROXY:-}
      https_proxy: ${HTTPS_PROXY:-}
      ftp_proxy: ${FTP_PROXY:-}
      no_proxy: ${NO_PROXY:-}
    ports:
      - ${API_LLM_PORT}:8000
    user: ${USERNAME}
    working_dir: /teramatsu/qlora
    volumes:
      - ./:/teramatsu/qlora
    tty: true
    logging:
      driver: json-file
      options:
        max-file: '5'
        max-size: '10m'
  fake-news-ui:
    container_name: fake-news-ui
    hostname: fake-news-ui
    build:
      context: ./ui
      dockerfile: Dockerfile
      args:
        UID: ${UID}
        USERNAME: ${USERNAME}
        GID: ${GID}
        GROUPNAME: ${GROUPNAME}
        HTTP_PROXY: ${HTTP_PROXY:-}
        HTTPS_PROXY: ${HTTPS_PROXY:-}
        FTP_PROXY: ${FTP_PROXY:-}
        NO_PROXY: ${NO_PROXY:-}
        http_proxy: ${HTTP_PROXY:-}
        https_proxy: ${HTTPS_PROXY:-}
        ftp_proxy: ${FTP_PROXY:-}
        no_proxy: ${NO_PROXY:-}
    environment:
      HTPP_PROXY: ${HTPP_PROXY:-}
      HTTPS_PROXY: ${HTTPS_PROXY:-}
      FTP_PROXY: ${FTP_PROXY:-}
      NO_PROXY: ${NO_PROXY:-}
      http_proxy: ${HTTP_PROXY:-}
      https_proxy: ${HTTPS_PROXY:-}
      ftp_proxy: ${FTP_PROXY:-}
      no_proxy: ${NO_PROXY:-}
    ports:
      - ${API_LLM_PORT}:8000
    user: ${USERNAME}
    working_dir: /teramatsu/qlora
    volumes:
      - ./:/teramatsu/qlora
    tty: true
    logging:
      driver: json-file
      options:
        max-file: '5'
        max-size: '10m'